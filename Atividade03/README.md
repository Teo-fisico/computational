## üß† Resumo de Redes Neurais

As **Redes Neurais Artificiais (RNAs)** s√£o modelos computacionais inspirados no funcionamento do c√©rebro humano, utilizados principalmente para tarefas de **aprendizado supervisionado e n√£o supervisionado**, como classifica√ß√£o, regress√£o, detec√ß√£o de padr√µes, tradu√ß√£o autom√°tica, reconhecimento de fala e imagens, entre outros.

### üß© Estrutura B√°sica

- **Neuronios (ou unidades)**: recebem entradas, aplicam pesos, somam e passam por uma fun√ß√£o de ativa√ß√£o.
- **Camadas**:
  - **Entrada (Input Layer)**: recebe os dados.
  - **Ocultas (Hidden Layers)**: fazem o processamento intermedi√°rio.
  - **Sa√≠da (Output Layer)**: produz o resultado final.
- **Pesos e Biases**: par√¢metros trein√°veis que determinam como a rede transforma os dados.

### ‚öôÔ∏è Funcionamento

1. **Forward Propagation**: os dados entram e passam pelas camadas at√© a sa√≠da.
2. **Fun√ß√£o de perda (Loss Function)**: calcula o erro entre a sa√≠da da rede e o valor real.
3. **Backpropagation**: o erro √© propagado para ajustar os pesos usando **gradientes**.
4. **Otimiza√ß√£o**: algoritmos como **Gradient Descent** ou **Adam** atualizam os pesos para minimizar a perda.

### üî• Tipos Comuns de Redes Neurais

| Tipo                        | Aplica√ß√£o Principal                     |
|-----------------------------|------------------------------------------|
| **Perceptron Multicamadas (MLP)** | Classifica√ß√£o, regress√£o                |
| **Convolucional (CNN)**         | Vis√£o computacional (imagens, v√≠deos)   |
| **Recorrente (RNN, LSTM, GRU)** | Sequ√™ncias temporais (texto, √°udio)     |
| **Transformers**               | NLP, tradu√ß√£o autom√°tica, LLMs          |
| **Autoencoders**              | Compress√£o, redu√ß√£o de dimensionalidade  |
| **GANs (Redes Generativas)**  | Gera√ß√£o de imagens, dados sint√©ticos     |

### üßÆ Fun√ß√µes de Ativa√ß√£o

- **ReLU**: \( f(x) = \max(0, x) \) (mais usada em redes profundas)
- **Sigmoid**: sa√≠da entre 0 e 1 (problemas bin√°rios)
- **Tanh**: sa√≠da entre -1 e 1
- **Softmax**: transforma vetores em probabilidades (multi-classe)

### üìà Treinamento

- **Dados de entrada** (X) e sa√≠das esperadas (Y)
- Divis√£o: treino, valida√ß√£o e teste
- **√âpocas**: n√∫mero de vezes que a rede v√™ todos os dados
- **Batch size**: n√∫mero de amostras por atualiza√ß√£o
- **Overfitting**: quando a rede aprende demais os dados de treino ‚Äî prevenir com regulariza√ß√£o, dropout, etc.

---
## üîç Scikit-learn ‚Äî Biblioteca de Machine Learning em Python

**Scikit-learn** √© uma biblioteca open-source voltada para **aprendizado de m√°quina (machine learning)** cl√°ssico. Baseada em NumPy, SciPy e matplotlib, √© amplamente utilizada por sua **facilidade de uso, desempenho e integra√ß√£o com o ecossistema cient√≠fico Python**.

### üß† Principais Funcionalidades

- **Modelos Supervisionados**:
  - Classifica√ß√£o: `LogisticRegression`, `RandomForestClassifier`, `SVC`, etc.
  - Regress√£o: `LinearRegression`, `Ridge`, `SVR`, etc.
- **Modelos N√£o Supervisionados**:
  - Clustering: `KMeans`, `DBSCAN`, `AgglomerativeClustering`
  - Redu√ß√£o de dimensionalidade: `PCA`, `TSNE`
- **Pr√©-processamento de Dados**:
  - Normaliza√ß√£o, padroniza√ß√£o: `StandardScaler`, `MinMaxScaler`
  - Codifica√ß√£o de vari√°veis: `OneHotEncoder`, `LabelEncoder`
  - Transforma√ß√µes: `PolynomialFeatures`, `PowerTransformer`
- **Sele√ß√£o de Modelos**:
  - Valida√ß√£o cruzada: `cross_val_score`, `GridSearchCV`, `RandomizedSearchCV`
  - Pipelines para encadeamento de etapas
- **M√©tricas de Avalia√ß√£o**:
  - Acur√°cia, precis√£o, recall, f1-score, curva ROC, matriz de confus√£o, etc.

---

## üî• PyTorch ‚Äî Framework de Deep Learning Flex√≠vel e Poderoso

**PyTorch** √© um framework de **aprendizado profundo (deep learning)** desenvolvido pelo Facebook AI Research. √â conhecido por sua **flexibilidade, c√≥digo limpo e execu√ß√£o din√¢mica**, o que o torna muito popular em pesquisa e prototipagem r√°pida.

### üß† Principais Caracter√≠sticas

- **Tensores**: estrutura de dados similar ao NumPy, mas com suporte a GPU.
- **Autograd**: sistema de diferencia√ß√£o autom√°tica para treinar redes neurais.
- **Rede Neural Modular**: uso de `torch.nn` para definir modelos customizados.
- **Treinamento Din√¢mico**: define-by-run (gr√°ficos computacionais din√¢micos).
- **Integra√ß√£o com CUDA**: f√°cil uso de GPUs para acelera√ß√£o.
- **Comunidade ativa e grande ecossistema**: TorchVision, TorchText, TorchAudio, etc.
---

## üß† TensorFlow ‚Äî Framework de Deep Learning Escal√°vel e de Produ√ß√£o

**TensorFlow** √© um framework open-source desenvolvido pelo **Google** para **aprendizado de m√°quina e deep learning**. Projetado para rodar de forma eficiente em CPUs, GPUs e TPUs, √© altamente utilizado em ambientes de **produ√ß√£o, pesquisa e dispositivos m√≥veis**.

### üåü Principais Caracter√≠sticas

- **Desenvolvimento e Produ√ß√£o**: ideal para escalar modelos em servidores, edge devices e navegadores.
- **Keras**: API de alto n√≠vel integrada ao TensorFlow para constru√ß√£o r√°pida de modelos.
- **Execu√ß√£o Eager e Grafos**: combina facilidade de prototipa√ß√£o com desempenho otimizado.
- **Suporte a GPU/TPU**: paraleliza√ß√£o e acelera√ß√£o autom√°tica.
- **Ferramentas adicionais**: TensorBoard (visualiza√ß√£o), TensorFlow Lite (mobile), TensorFlow.js (web), TF-Serving (deploy).
---